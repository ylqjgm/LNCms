# TASK002-50: 数据库设计 - 采集模块 - 采集数据表

## 任务信息

**任务编号**: TASK002-50  
**父任务**: TASK002  
**任务名称**: 数据库设计 - 采集模块 - 采集数据表  
**版本信息**: v1.0.0  
**当前状态**: 计划中  
**创建时间**: 2026-01-02 22:13:54 CST

## 任务描述

设计采集模块的采集数据表（crawler_data），用于存储采集任务采集到的数据信息。必须遵循 PostgreSQL 数据库设计规范，包含完整的字段定义、约束、索引、注释等。

## 依赖任务

TASK002-49（采集规则表）、TASK002-50（采集任务表）

## 实现指南

### 1. 分析需求文档

阅读 `docs/Requirements/Crawler.md` 文档，了解采集数据管理的详细需求：
- 采集数据管理：采集数据存储、采集数据查询、采集数据处理
- 采集数据关联采集任务和采集规则
- 采集数据需要支持原始数据和处理后数据
- 采集数据需要支持数据状态管理

### 2. 设计采集数据表结构

设计 `crawler_data` 表，包含采集数据基本信息：

```sql
CREATE TABLE crawler_data (
    id BIGSERIAL PRIMARY KEY,
    task_id BIGINT NOT NULL,
    rule_id BIGINT NOT NULL,
    data_type VARCHAR(20) NOT NULL,
    source_id VARCHAR(200),
    source_url VARCHAR(500),
    raw_data JSONB,
    processed_data JSONB,
    data_status VARCHAR(20) NOT NULL DEFAULT 'pending',
    process_status VARCHAR(20) NOT NULL DEFAULT 'pending',
    error_message TEXT,
    collected_at TIMESTAMPTZ,
    processed_at TIMESTAMPTZ,
    created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
    CONSTRAINT fk_crawler_data_task_id FOREIGN KEY (task_id) REFERENCES crawler_tasks(id) ON DELETE CASCADE,
    CONSTRAINT fk_crawler_data_rule_id FOREIGN KEY (rule_id) REFERENCES crawler_rules(id) ON DELETE RESTRICT,
    CONSTRAINT ck_crawler_data_data_type CHECK (data_type IN ('novel', 'comic', 'audio', 'video', 'other')),
    CONSTRAINT ck_crawler_data_data_status CHECK (data_status IN ('pending', 'collected', 'processed', 'failed', 'skipped')),
    CONSTRAINT ck_crawler_data_process_status CHECK (process_status IN ('pending', 'processing', 'completed', 'failed', 'skipped'))
);

-- 创建索引
CREATE INDEX idx_crawler_data_task_id ON crawler_data(task_id);
CREATE INDEX idx_crawler_data_rule_id ON crawler_data(rule_id);
CREATE INDEX idx_crawler_data_data_type ON crawler_data(data_type);
CREATE INDEX idx_crawler_data_source_id ON crawler_data(source_id);
CREATE INDEX idx_crawler_data_data_status ON crawler_data(data_status);
CREATE INDEX idx_crawler_data_process_status ON crawler_data(process_status);
CREATE INDEX idx_crawler_data_collected_at ON crawler_data(collected_at);
CREATE INDEX idx_crawler_data_created_at ON crawler_data(created_at);
CREATE INDEX idx_crawler_data_task_status ON crawler_data(task_id, data_status);
CREATE INDEX idx_crawler_data_rule_status ON crawler_data(rule_id, data_status);
CREATE INDEX idx_crawler_data_task_type ON crawler_data(task_id, data_type);

-- 为 JSONB 字段创建 GIN 索引（用于高效查询）
CREATE INDEX idx_crawler_data_raw_data ON crawler_data USING GIN (raw_data);
CREATE INDEX idx_crawler_data_processed_data ON crawler_data USING GIN (processed_data);

-- 创建触发器自动更新 updated_at
CREATE OR REPLACE FUNCTION update_crawler_data_updated_at()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER update_crawler_data_updated_at
    BEFORE UPDATE ON crawler_data
    FOR EACH ROW
    EXECUTE FUNCTION update_crawler_data_updated_at();

-- 添加表注释
COMMENT ON TABLE crawler_data IS '采集数据表，存储采集任务采集到的数据信息';
COMMENT ON COLUMN crawler_data.id IS '数据ID，自增主键';
COMMENT ON COLUMN crawler_data.task_id IS '任务ID，外键关联crawler_tasks表';
COMMENT ON COLUMN crawler_data.rule_id IS '规则ID，外键关联crawler_rules表';
COMMENT ON COLUMN crawler_data.data_type IS '数据类型：novel-小说、comic-漫画、audio-音频、video-视频、other-其他';
COMMENT ON COLUMN crawler_data.source_id IS '源数据ID，采集源的数据唯一标识符';
COMMENT ON COLUMN crawler_data.source_url IS '源数据URL，采集源的数据地址';
COMMENT ON COLUMN crawler_data.raw_data IS '原始数据，JSONB格式，存储采集到的原始数据';
COMMENT ON COLUMN crawler_data.processed_data IS '处理后数据，JSONB格式，存储处理后的结构化数据';
COMMENT ON COLUMN crawler_data.data_status IS '数据状态：pending-待采集、collected-已采集、processed-已处理、failed-失败、skipped-已跳过';
COMMENT ON COLUMN crawler_data.process_status IS '处理状态：pending-待处理、processing-处理中、completed-已完成、failed-失败、skipped-已跳过';
COMMENT ON COLUMN crawler_data.error_message IS '错误消息，采集或处理失败时的错误信息';
COMMENT ON COLUMN crawler_data.collected_at IS '采集时间，数据采集完成时的时间';
COMMENT ON COLUMN crawler_data.processed_at IS '处理时间，数据处理完成时的时间';
COMMENT ON COLUMN crawler_data.created_at IS '创建时间，自动设置为当前时间';
COMMENT ON COLUMN crawler_data.updated_at IS '更新时间，每次更新时自动更新';
```

### 3. 设计约束

- **主键约束**：`pk_crawler_data` (id)
- **外键约束**：`fk_crawler_data_task_id` (task_id) 关联 crawler_tasks(id)，级联删除
- **外键约束**：`fk_crawler_data_rule_id` (rule_id) 关联 crawler_rules(id)，删除时禁止（RESTRICT）
- **检查约束**：`ck_crawler_data_data_type` (data_type) - 确保数据类型是预定义的值
- **检查约束**：`ck_crawler_data_data_status` (data_status) - 确保数据状态是预定义的值
- **检查约束**：`ck_crawler_data_process_status` (process_status) - 确保处理状态是预定义的值
- **非空约束**：task_id、rule_id、data_type、data_status、process_status 必须非空
- **默认值**：data_status 默认为 'pending'，process_status 默认为 'pending'
- **可选字段**：source_id、source_url、raw_data、processed_data、error_message、collected_at、processed_at 可为 NULL

### 4. 设计索引

- **主键索引**：`pk_crawler_data` (id) - 自动创建
- **外键索引**：`idx_crawler_data_task_id` (task_id) - 用于查询任务的数据
- **外键索引**：`idx_crawler_data_rule_id` (rule_id) - 用于查询规则的数据
- **普通索引**：`idx_crawler_data_data_type` (data_type) - 用于按数据类型筛选
- **普通索引**：`idx_crawler_data_source_id` (source_id) - 用于按源数据ID查询
- **普通索引**：`idx_crawler_data_data_status` (data_status) - 用于按数据状态筛选
- **普通索引**：`idx_crawler_data_process_status` (process_status) - 用于按处理状态筛选
- **普通索引**：`idx_crawler_data_collected_at` (collected_at) - 用于按采集时间排序
- **普通索引**：`idx_crawler_data_created_at` (created_at) - 用于按创建时间排序
- **GIN 索引**：`idx_crawler_data_raw_data` (raw_data) - 用于高效查询 JSONB 原始数据
- **GIN 索引**：`idx_crawler_data_processed_data` (processed_data) - 用于高效查询 JSONB 处理后数据
- **复合索引**：`idx_crawler_data_task_status` (task_id, data_status) - 用于查询任务的特定状态数据
- **复合索引**：`idx_crawler_data_rule_status` (rule_id, data_status) - 用于查询规则的特定状态数据
- **复合索引**：`idx_crawler_data_task_type` (task_id, data_type) - 用于查询任务的特定类型数据

### 5. 考虑性能优化

- 为 task_id 和 rule_id 创建索引，支持关联查询
- 为 data_type、data_status、process_status 创建索引，支持按类型和状态筛选查询
- 为 source_id 创建索引，支持按源数据ID查询（用于去重）
- 为 collected_at 和 created_at 创建索引，支持时间排序查询
- 为 raw_data 和 processed_data 创建 GIN 索引，支持高效查询 JSONB 数据
- 使用复合索引优化常用查询场景（如查询任务的特定状态数据、查询规则的特定状态数据、查询任务的特定类型数据）
- 使用触发器自动更新 updated_at 字段
- 采集数据表数据量大，考虑使用分区表（按任务ID或时间分区）

### 6. 查询示例

```sql
-- 查询任务的所有已采集数据
SELECT * FROM crawler_data
WHERE task_id = 1 
  AND data_status = 'collected'
ORDER BY collected_at DESC;

-- 查询规则的特定类型数据
SELECT * FROM crawler_data
WHERE rule_id = 1 
  AND data_type = 'novel'
ORDER BY created_at DESC;

-- 查询任务的待处理数据
SELECT * FROM crawler_data
WHERE task_id = 1 
  AND process_status = 'pending'
ORDER BY created_at ASC;
```

## 验收标准

1. 表结构设计完整，包含所有必要字段
2. 所有字段都有适当的类型、约束和默认值
3. 外键约束正确，关联 crawler_tasks 表和 crawler_rules 表
4. 检查约束正确，确保数据类型、数据状态、处理状态等是有效的值
5. 索引设计合理，支持常用查询场景（包括按任务查询、按规则查询、按数据类型查询、按状态查询）
6. 为 JSONB 字段创建 GIN 索引，支持高效查询原始数据和处理后数据
7. 表注释和字段注释完整，使用中文
8. 触发器正确创建，自动更新 updated_at 字段
9. 表设计符合 PostgreSQL 数据库设计规范
10. 考虑采集数据表数据量大，建议使用分区表（按任务ID或时间分区）

## 相关文件

- `docs/Requirements/Crawler.md` - 采集模块需求文档
- `.cursor/rules/database.mdc` - PostgreSQL 数据库设计规范
- `docs/TASKS/TASK002/TASK002.md` - 主任务文档
- `docs/TASKS/TASK002/TASK002-49.md` - 采集规则表设计文档
- `docs/TASKS/TASK002/TASK002-50.md` - 采集任务表设计文档

## Git 提交信息任务

任务完成后，需要生成 Git 提交信息。请根据实际修改内容生成合适的提交信息。

---

**文档版本**: 1.0  
**最后更新**: 2026-01-02 22:13:54 CST

